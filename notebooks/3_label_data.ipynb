{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Dataset \n",
    "\n",
    "This notebook enables users to manually label the dataset as one of these three labels: \n",
    "\n",
    "- Positive: Positively promoting the brand\n",
    "- Negative: Negatively promoting the brand\n",
    "- Neutral: Doesn't fit into either of these categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# set this on the path so that we can reference the commong data locations\n",
    "sys.path.append(\"../scripts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 'reddit_filtered_data.csv' into a DataFrame!\n"
     ]
    }
   ],
   "source": [
    "from access_data import authenticate_google_drive, grab_google_drive_folder_data\n",
    "\n",
    "drive = authenticate_google_drive()\n",
    "df = grab_google_drive_folder_data(drive=drive,filename=\"reddit_filtered_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>subreddit_topic</th>\n",
       "      <th>search_query</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>username</th>\n",
       "      <th>created_at</th>\n",
       "      <th>data_pull_date</th>\n",
       "      <th>days_since_post_date</th>\n",
       "      <th>combine_text</th>\n",
       "      <th>flag_picture_posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1gum4oc</td>\n",
       "      <td>FirstTimeHomeBuyer</td>\n",
       "      <td>Rocket Mortgage</td>\n",
       "      <td>Is rocket mortgage that bad?</td>\n",
       "      <td>I’m in the market to buy a house now (21m). I ...</td>\n",
       "      <td>https://www.reddit.com/r/FirstTimeHomeBuyer/co...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>Valuable-Pilot-2818</td>\n",
       "      <td>2024-11-19 01:59:25</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>134</td>\n",
       "      <td>Is rocket mortgage that bad?. I’m in the marke...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1541el1</td>\n",
       "      <td>FirstTimeHomeBuyer</td>\n",
       "      <td>Rocket Mortgage</td>\n",
       "      <td>WARNING- do NOT work with rocket mortgage!!!</td>\n",
       "      <td>EDIT: there is an extreme lack of transparency...</td>\n",
       "      <td>https://www.reddit.com/r/FirstTimeHomeBuyer/co...</td>\n",
       "      <td>594</td>\n",
       "      <td>471</td>\n",
       "      <td>justmeAlonekitty</td>\n",
       "      <td>2023-07-19 17:31:01</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>623</td>\n",
       "      <td>WARNING- do NOT work with rocket mortgage!!!. ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1hqgmvb</td>\n",
       "      <td>FirstTimeHomeBuyer</td>\n",
       "      <td>Rocket Mortgage</td>\n",
       "      <td>Avoid Rocket Mortgage</td>\n",
       "      <td>I have a RM mortgage and they call me once a y...</td>\n",
       "      <td>https://www.reddit.com/r/FirstTimeHomeBuyer/co...</td>\n",
       "      <td>607</td>\n",
       "      <td>191</td>\n",
       "      <td>maz4499</td>\n",
       "      <td>2024-12-31 15:12:06</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>92</td>\n",
       "      <td>Avoid Rocket Mortgage. I have a RM mortgage an...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1doitpg</td>\n",
       "      <td>FirstTimeHomeBuyer</td>\n",
       "      <td>Rocket Mortgage</td>\n",
       "      <td>Rocket Mortgage Everybody</td>\n",
       "      <td>Took all of my financial information and would...</td>\n",
       "      <td>https://www.reddit.com/gallery/1doitpg</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>varicoseballs</td>\n",
       "      <td>2024-06-25 22:31:06</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>281</td>\n",
       "      <td>Rocket Mortgage Everybody. Took all of my fina...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1b3xvqv</td>\n",
       "      <td>FirstTimeHomeBuyer</td>\n",
       "      <td>Rocket Mortgage</td>\n",
       "      <td>Rocket Mortgage: An honest review</td>\n",
       "      <td>As a first time home buyer and a first generat...</td>\n",
       "      <td>https://www.reddit.com/r/FirstTimeHomeBuyer/co...</td>\n",
       "      <td>36</td>\n",
       "      <td>71</td>\n",
       "      <td>Separate_Bar685</td>\n",
       "      <td>2024-03-01 16:04:32</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>397</td>\n",
       "      <td>Rocket Mortgage: An honest review. As a first ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  submission_id     subreddit_topic     search_query  \\\n",
       "0       1gum4oc  FirstTimeHomeBuyer  Rocket Mortgage   \n",
       "1       1541el1  FirstTimeHomeBuyer  Rocket Mortgage   \n",
       "2       1hqgmvb  FirstTimeHomeBuyer  Rocket Mortgage   \n",
       "3       1doitpg  FirstTimeHomeBuyer  Rocket Mortgage   \n",
       "4       1b3xvqv  FirstTimeHomeBuyer  Rocket Mortgage   \n",
       "\n",
       "                                          title  \\\n",
       "0                  Is rocket mortgage that bad?   \n",
       "1  WARNING- do NOT work with rocket mortgage!!!   \n",
       "2                         Avoid Rocket Mortgage   \n",
       "3                     Rocket Mortgage Everybody   \n",
       "4             Rocket Mortgage: An honest review   \n",
       "\n",
       "                                                text  \\\n",
       "0  I’m in the market to buy a house now (21m). I ...   \n",
       "1  EDIT: there is an extreme lack of transparency...   \n",
       "2  I have a RM mortgage and they call me once a y...   \n",
       "3  Took all of my financial information and would...   \n",
       "4  As a first time home buyer and a first generat...   \n",
       "\n",
       "                                                 url  score  num_comments  \\\n",
       "0  https://www.reddit.com/r/FirstTimeHomeBuyer/co...      0            21   \n",
       "1  https://www.reddit.com/r/FirstTimeHomeBuyer/co...    594           471   \n",
       "2  https://www.reddit.com/r/FirstTimeHomeBuyer/co...    607           191   \n",
       "3             https://www.reddit.com/gallery/1doitpg      0            23   \n",
       "4  https://www.reddit.com/r/FirstTimeHomeBuyer/co...     36            71   \n",
       "\n",
       "              username           created_at data_pull_date  \\\n",
       "0  Valuable-Pilot-2818  2024-11-19 01:59:25     2025-04-02   \n",
       "1     justmeAlonekitty  2023-07-19 17:31:01     2025-04-02   \n",
       "2              maz4499  2024-12-31 15:12:06     2025-04-02   \n",
       "3        varicoseballs  2024-06-25 22:31:06     2025-04-02   \n",
       "4      Separate_Bar685  2024-03-01 16:04:32     2025-04-02   \n",
       "\n",
       "   days_since_post_date                                       combine_text  \\\n",
       "0                   134  Is rocket mortgage that bad?. I’m in the marke...   \n",
       "1                   623  WARNING- do NOT work with rocket mortgage!!!. ...   \n",
       "2                    92  Avoid Rocket Mortgage. I have a RM mortgage an...   \n",
       "3                   281  Rocket Mortgage Everybody. Took all of my fina...   \n",
       "4                   397  Rocket Mortgage: An honest review. As a first ...   \n",
       "\n",
       "   flag_picture_posts  \n",
       "0               False  \n",
       "1               False  \n",
       "2               False  \n",
       "3               False  \n",
       "4               False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a folder labeled: `labeled_data/` in here locally if you'd like to run this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "class show_visual(): \n",
    "    def __init__(self, df, file_number=1, reviewer=\"aserban\"):\n",
    "        self.df = df\n",
    "        self.labels = {}  # Store labeled data\n",
    "        self.batch_size = 5\n",
    "        self.current_index = 0  # Track progress\n",
    "        self.label_options = [ 'Unknown', 'Positive', 'Negative', 'Neutral']\n",
    "        self.label_widgets = []\n",
    "\n",
    "        self.next_button = widgets.Button(description=\"Next Batch\", button_style='success', layout=widgets.Layout(width='200px', height='50px'))\n",
    "        self.save_button = widgets.Button(description=\"Save & Exit\", button_style='danger', layout=widgets.Layout(width='200px', height='50px'))\n",
    "        self.reviewer = reviewer\n",
    "        self.file_name = f\"labeled_data/{reviewer}_labeled_data_{file_number}.csv\"\n",
    "\n",
    "        self.selected_columns = ['submission_id', 'subredit_topic', 'search_query', 'combine_text', 'url', 'label', 'reviewer']\n",
    "        \n",
    "    # Function to display the current batch\n",
    "    def show_batch(self):\n",
    "        clear_output(wait=True)\n",
    "        if self.current_index >= len(self.df):\n",
    "            print(\"All samples labeled!\")\n",
    "            return\n",
    "        \n",
    "        batch_end = min(self.current_index + self.batch_size, len(self.df))\n",
    "        current_batch = self.df.iloc[self.current_index:batch_end]\n",
    "        \n",
    "        self.label_widgets.clear()        \n",
    "        for i, row in current_batch.iterrows():\n",
    "            dropdown = widgets.Dropdown(\n",
    "                options=self.label_options,\n",
    "                description=f\"Label: \",\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='700px')\n",
    "            )\n",
    "            self.label_widgets.append((i, dropdown))\n",
    "            print(f\"Post Number Index: {i}\")\n",
    "\n",
    "            display(widgets.VBox([\n",
    "                widgets.HTML(f\"Brand: <b><font color='red'>{row['search_query']}</font></b><br><br>{row['combine_text']} <br>\"),\n",
    "                widgets.Label(f\"{row['url']}\", layout=widgets.Layout(width='1000px', word_wrap='break-word')),\n",
    "                dropdown\n",
    "            ]))\n",
    "        \n",
    "        display(widgets.HBox([self.next_button, self.save_button]))\n",
    "\n",
    "    # Function to determine whether to save labels and proceed\n",
    "    def save_labels(self,continue_labeling=True):\n",
    "        for index, dropdown in self.label_widgets:\n",
    "            self.labels[index] = dropdown.value\n",
    "        \n",
    "        self.current_index += self.batch_size\n",
    "        if continue_labeling:\n",
    "            self.show_batch()\n",
    "        else:\n",
    "            self.save_data()\n",
    "\n",
    "    # Function to save labeled data locally\n",
    "    def save_data(self):\n",
    "        labeled_df = self.df.copy()\n",
    "        labeled_df['label'] = labeled_df.index.map(self.labels)\n",
    "        labeled_df['reviewer'] = self.reviewer\n",
    "\n",
    "        selected_df = labeled_df[~labeled_df['label'].isna()].reset_index(drop=True)\n",
    "        # selected columns \n",
    "        selected_df = selected_df[self.selected_columns]\n",
    "\n",
    "        selected_df.to_csv(self.file_name, index=False)\n",
    "        print(f\"Data saved as '{self.file_name}'\")\n",
    "\n",
    "\n",
    "    def start_manually_labelling(self): \n",
    "        \n",
    "        # Bind buttons\n",
    "        self.next_button.on_click(lambda _: self.save_labels(True))\n",
    "        self.save_button.on_click(lambda _: self.save_labels(False))\n",
    "\n",
    "        # Start labeling\n",
    "        self.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sv = show_visual(df=df, file_number=1, reviewer=\"aserban\")\n",
    "# sv.start_manually_labelling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sv = show_visual(df=df.sample(20, random_state=42), file_number=2, reviewer=\"aserban\")\n",
    "# sv.start_manually_labelling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sv = show_visual(df=df.sample(100, random_state=13), file_number=3, reviewer=\"aserban\")\n",
    "# sv.start_manually_labelling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sv = show_visual(df=df.sample(100, random_state=7), file_number=4, reviewer=\"aserban\")\n",
    "# sv.start_manually_labelling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path_check = \"labeled_data/aserban_labeled_data_3.csv\"\n",
    "# check_df = pd.read_csv(file_path_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Labeled Data \n",
    "\n",
    "After we saved the files locally, we the imported it into another folder within google drive, and this is how we combiend the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../scripts/\")\n",
    "\n",
    "from access_data import authenticate_google_drive, grab_google_drive_folder_data\n",
    "\n",
    "drive = authenticate_google_drive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "labeled_data_folder_location_file = \"credentials/google_drive_labeled_data_folder_id.json\"\n",
    "\n",
    "\n",
    "with open(labeled_data_folder_location_file, 'r') as file:\n",
    "    google_drive_credentials = json.load(file)\n",
    "folder_id = google_drive_credentials[\"folder_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = drive.ListFile({'q': f\"'{folder_id}' in parents and trashed=false\"}).GetList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 'chrismca_labeled_data_5.csv' into a DataFrame!\n",
      "Successfully loaded 'chrismca_labeled_data_10.csv' into a DataFrame!\n",
      "Successfully loaded 'chrismca_labeled_data_9.csv' into a DataFrame!\n",
      "Successfully loaded 'chrismca_labeled_data_8.csv' into a DataFrame!\n",
      "Successfully loaded 'chrismca_labeled_data_7.csv' into a DataFrame!\n",
      "Successfully loaded 'chrismca_labeled_data_6.csv' into a DataFrame!\n",
      "Successfully loaded 'chrismca_labeled_data_3.csv' into a DataFrame!\n",
      "Successfully loaded 'chrismca_labeled_data_2.csv' into a DataFrame!\n",
      "Successfully loaded 'chrismca_labeled_data_4.csv' into a DataFrame!\n",
      "Successfully loaded 'chriscma_labeled_data_1.csv' into a DataFrame!\n",
      "Successfully loaded 'aserban_labeled_data_3.csv' into a DataFrame!\n",
      "Successfully loaded 'aserban_labeled_data_2.csv' into a DataFrame!\n",
      "Successfully loaded 'aserban_labeled_data_1.csv' into a DataFrame!\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all files and combine\n",
    "combined_labeled_data = pd.DataFrame()\n",
    "for file in file_list: \n",
    "    file_name = file['title']        \n",
    "    file_df = grab_google_drive_folder_data(drive=drive,credential_file=labeled_data_folder_location_file,filename=file_name)\n",
    "    file_df = file_df[file_df['label'] != 'Unknown'].reset_index(drop=True)\n",
    "    if combined_labeled_data.empty : \n",
    "        combined_labeled_data = file_df \n",
    "    else: \n",
    "        combined_labeled_data  = pd.concat([combined_labeled_data, file_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leverage combine_text from df rather than labeled_data\n",
    "combined_labeled_data = combined_labeled_data.rename(columns={'subredit_topic': 'subreddit_topic'})\n",
    "columns = ['submission_id', 'subreddit_topic', 'search_query', 'label', 'reviewer']\n",
    "\n",
    "combined_labeled_data = combined_labeled_data[columns]\n",
    "df_subset = df[['submission_id', 'subreddit_topic', 'search_query', 'combine_text', 'url']]\n",
    "\n",
    "labeled_data = combined_labeled_data.merge(df_subset, on=['submission_id', 'subreddit_topic', 'search_query'], how='left')\n",
    "labeled_data = labeled_data[['submission_id', 'subreddit_topic', 'search_query', 'combine_text', 'url', 'label', 'reviewer']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop where it is in labeled but not in df \n",
    "labeled_data = labeled_data[~labeled_data['combine_text'].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conflicting labels:   1\n"
     ]
    }
   ],
   "source": [
    "# Make sure there are no duplicates in labeling \n",
    "combined_labeled_data_grouped = pd.DataFrame(labeled_data.groupby(['submission_id','subreddit_topic','search_query', 'combine_text', 'url']).agg({'label': ['count', 'min', 'max']})).reset_index()\n",
    "combined_labeled_data_grouped.columns = ['_'.join(col) for col in combined_labeled_data_grouped.columns]\n",
    "\n",
    "# Check if there are instances that the labels are not the same \n",
    "combined_labeled_data_grouped[combined_labeled_data_grouped['label_count'] > 1]\n",
    "combined_labeled_data_grouped['same_value'] = combined_labeled_data_grouped['label_min'] == combined_labeled_data_grouped['label_max']\n",
    "print(\"Number of conflicting labels:  \", combined_labeled_data_grouped[~combined_labeled_data_grouped['same_value']].shape[0])\n",
    "\n",
    "# Drop instances where the label was conflicting\n",
    "conflicting_submission_ids = list(combined_labeled_data_grouped[~combined_labeled_data_grouped['same_value']]['submission_id_'])\n",
    "labeled_data = labeled_data[~labeled_data['submission_id'].isin(conflicting_submission_ids)].reset_index(drop=True)\n",
    "\n",
    "# The ones that have more than 1 and are the same value , coalesce those \n",
    "labeled_data = labeled_data.drop_duplicates(\n",
    "    subset=['submission_id', 'subreddit_topic', 'search_query', 'combine_text', 'url'], \n",
    "    keep='first'\n",
    ").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conflicting labels:   1\n"
     ]
    }
   ],
   "source": [
    "combined_labeled_data_grouped['same_value'] = combined_labeled_data_grouped['label_min'] == combined_labeled_data_grouped['label_max']\n",
    "print(\"Number of conflicting labels:  \", combined_labeled_data_grouped[~combined_labeled_data_grouped['same_value']].shape[0])\n",
    "\n",
    "# Drop instances where the label was conflicting\n",
    "conflicting_submission_ids = list(combined_labeled_data_grouped[~combined_labeled_data_grouped['same_value']]['submission_id_'])\n",
    "labeled_data = labeled_data[~labeled_data['submission_id'].isin(conflicting_submission_ids)].reset_index(drop=True)\n",
    "\n",
    "# The ones that have more than 1 and are the same value , coalesce those \n",
    "labeled_data = labeled_data.drop_duplicates(\n",
    "    subset=['submission_id', 'subreddit_topic', 'search_query', 'combine_text', 'url'], \n",
    "    keep='first'\n",
    ").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral     78\n",
      "Negative    15\n",
      "Positive     2\n",
      "Name: label, dtype: int64\n",
      "\n",
      "\n",
      "Neutral     0.821053\n",
      "Negative    0.157895\n",
      "Positive    0.021053\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# See the distribution of the labels \n",
    "print(labeled_data['label'].value_counts(dropna=False) )\n",
    "print('\\n')\n",
    "print(labeled_data['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final file size:  95\n"
     ]
    }
   ],
   "source": [
    "print(\"Final file size: \",  labeled_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'combined_labeled_data.csv' uploaded successfully to folder 1Ktcv4eaR7kH0teyGuLph4LSYWxI1qkIS!\n"
     ]
    }
   ],
   "source": [
    "from access_data import  save_google_drive_data\n",
    "\n",
    "labeled_data_folder_location_file = \"credentials/google_drive_folder_id.json\"\n",
    "file_name_combined = \"combined_labeled_data.csv\"\n",
    "\n",
    "# Save the data in the Google Drive location\n",
    "save_google_drive_data(drive=drive, \n",
    "                       dataframe =labeled_data, \n",
    "                       filename=file_name_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
