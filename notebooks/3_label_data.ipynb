{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Dataset \n",
    "\n",
    "This notebook enables users to manually label the dataset as one of these three labels: \n",
    "\n",
    "- Positive: Positively promoting the brand\n",
    "- Negative: Negatively promoting the brand\n",
    "- Neutral: Doesn't fit into either of these categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# set this on the path so that we can reference the commong data locations\n",
    "sys.path.append(\"../scripts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 'reddit_filtered_data.csv' into a DataFrame!\n"
     ]
    }
   ],
   "source": [
    "from access_data import authenticate_google_drive, grab_google_drive_folder_data\n",
    "\n",
    "drive = authenticate_google_drive()\n",
    "df = grab_google_drive_folder_data(drive=drive,filename=\"reddit_filtered_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a folder labeled: `labeled_data/` in here locally if you'd like to run this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "class show_visual(): \n",
    "    def __init__(self, df, file_number=1, reviewer=\"aserban\"):\n",
    "        self.df = df\n",
    "        self.labels = {}  # Store labeled data\n",
    "        self.batch_size = 5\n",
    "        self.current_index = 0  # Track progress\n",
    "        self.label_options = [ 'Unknown', 'Positive', 'Negative', 'Neutral']\n",
    "        self.label_widgets = []\n",
    "\n",
    "        self.next_button = widgets.Button(description=\"Next Batch\", button_style='success', layout=widgets.Layout(width='200px', height='50px'))\n",
    "        self.save_button = widgets.Button(description=\"Save & Exit\", button_style='danger', layout=widgets.Layout(width='200px', height='50px'))\n",
    "        self.reviewer = reviewer\n",
    "        self.file_name = f\"labeled_data/{reviewer}_labeled_data_{file_number}.csv\"\n",
    "\n",
    "        self.selected_columns = ['submission_id', 'subredit_topic', 'search_query', 'combine_text', 'url', 'label', 'reviewer']\n",
    "        \n",
    "    # Function to display the current batch\n",
    "    def show_batch(self):\n",
    "        clear_output(wait=True)\n",
    "        if self.current_index >= len(self.df):\n",
    "            print(\"All samples labeled!\")\n",
    "            return\n",
    "        \n",
    "        batch_end = min(self.current_index + self.batch_size, len(self.df))\n",
    "        current_batch = self.df.iloc[self.current_index:batch_end]\n",
    "        \n",
    "        self.label_widgets.clear()        \n",
    "        for i, row in current_batch.iterrows():\n",
    "            dropdown = widgets.Dropdown(\n",
    "                options=self.label_options,\n",
    "                description=f\"Label: \",\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='700px')\n",
    "            )\n",
    "            self.label_widgets.append((i, dropdown))\n",
    "            print(f\"Post Number Index: {i}\")\n",
    "\n",
    "            display(widgets.VBox([\n",
    "                widgets.HTML(f\"Brand: <b><font color='red'>{row['search_query']}</font></b><br><br>{row['combine_text']} <br>\"),\n",
    "                widgets.Label(f\"{row['url']}\", layout=widgets.Layout(width='1000px', word_wrap='break-word')),\n",
    "                dropdown\n",
    "            ]))\n",
    "        \n",
    "        display(widgets.HBox([self.next_button, self.save_button]))\n",
    "\n",
    "    # Determine whether to save labels and proceed\n",
    "    def save_labels(self,continue_labeling=True):\n",
    "        for index, dropdown in self.label_widgets:\n",
    "            self.labels[index] = dropdown.value\n",
    "        \n",
    "        self.current_index += self.batch_size\n",
    "        if continue_labeling:\n",
    "            self.show_batch()\n",
    "        else:\n",
    "            self.save_data()\n",
    "\n",
    "    # Function to save labeled data locally\n",
    "    def save_data(self):\n",
    "        labeled_df = self.df.copy()\n",
    "        labeled_df['label'] = labeled_df.index.map(self.labels)\n",
    "        labeled_df['reviewer'] = self.reviewer\n",
    "\n",
    "        selected_df = labeled_df[~labeled_df['label'].isna()].reset_index(drop=True)\n",
    "        # selected columns \n",
    "        selected_df = selected_df[self.selected_columns]\n",
    "\n",
    "        selected_df.to_csv(self.file_name, index=False)\n",
    "        print(f\"Data saved as '{self.file_name}'\")\n",
    "\n",
    "\n",
    "    def start_manually_labelling(self): \n",
    "        \n",
    "        # Bind buttons\n",
    "        self.next_button.on_click(lambda _: self.save_labels(True))\n",
    "        self.save_button.on_click(lambda _: self.save_labels(False))\n",
    "\n",
    "        # Start labeling\n",
    "        self.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sv = show_visual(df=df, file_number=1, reviewer=\"aserban\")\n",
    "# sv.start_manually_labelling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sv = show_visual(df=df.sample(20, random_state=42), file_number=2, reviewer=\"aserban\")\n",
    "# sv.start_manually_labelling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sv = show_visual(df=df.sample(100, random_state=13), file_number=3, reviewer=\"aserban\")\n",
    "# sv.start_manually_labelling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sv = show_visual(df=df.sample(100, random_state=7), file_number=4, reviewer=\"aserban\")\n",
    "# sv.start_manually_labelling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path_check = \"labeled_data/aserban_labeled_data_3.csv\"\n",
    "# check_df = pd.read_csv(file_path_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Labeled Data \n",
    "\n",
    "After we saved the files locally, we the imported it into another folder within google drive, and this is how we combiend the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../scripts/\")\n",
    "\n",
    "from access_data import authenticate_google_drive, grab_google_drive_folder_data\n",
    "\n",
    "drive = authenticate_google_drive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "labeled_data_folder_location_file = \"credentials/google_drive_labeled_data_folder_id.json\"\n",
    "\n",
    "\n",
    "with open(labeled_data_folder_location_file, 'r') as file:\n",
    "    google_drive_credentials = json.load(file)\n",
    "folder_id = google_drive_credentials[\"folder_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = drive.ListFile({'q': f\"'{folder_id}' in parents and trashed=false\"}).GetList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 'chrismca_labeled_data_5.csv' into a DataFrame!\n",
      "Successfully loaded 'chrismca_labeled_data_10.csv' into a DataFrame!\n",
      "Successfully loaded 'chrismca_labeled_data_9.csv' into a DataFrame!\n",
      "Successfully loaded 'chrismca_labeled_data_8.csv' into a DataFrame!\n",
      "Successfully loaded 'chrismca_labeled_data_7.csv' into a DataFrame!\n",
      "Successfully loaded 'chrismca_labeled_data_6.csv' into a DataFrame!\n",
      "Successfully loaded 'chrismca_labeled_data_3.csv' into a DataFrame!\n",
      "Successfully loaded 'chrismca_labeled_data_2.csv' into a DataFrame!\n",
      "Successfully loaded 'chrismca_labeled_data_4.csv' into a DataFrame!\n",
      "Successfully loaded 'chriscma_labeled_data_1.csv' into a DataFrame!\n",
      "Successfully loaded 'aserban_labeled_data_3.csv' into a DataFrame!\n",
      "Successfully loaded 'aserban_labeled_data_2.csv' into a DataFrame!\n",
      "Successfully loaded 'aserban_labeled_data_1.csv' into a DataFrame!\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all files and combine\n",
    "combined_labeled_data = pd.DataFrame()\n",
    "for file in file_list: \n",
    "    file_name = file['title']        \n",
    "    file_df = grab_google_drive_folder_data(drive=drive,credential_file=labeled_data_folder_location_file,filename=file_name)\n",
    "    file_df = file_df[file_df['label'] != 'Unknown'].reset_index(drop=True)\n",
    "    if combined_labeled_data.empty : \n",
    "        combined_labeled_data = file_df \n",
    "    else: \n",
    "        combined_labeled_data  = pd.concat([combined_labeled_data, file_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leverage combine_text from df rather than labeled_data\n",
    "combined_labeled_data = combined_labeled_data.rename(columns={'subredit_topic': 'subreddit_topic'})\n",
    "columns = ['submission_id', 'subreddit_topic', 'search_query', 'label', 'reviewer']\n",
    "\n",
    "combined_labeled_data = combined_labeled_data[columns]\n",
    "df_subset = df[['submission_id', 'subreddit_topic', 'search_query', 'combine_text', 'url']]\n",
    "\n",
    "labeled_data = combined_labeled_data.merge(df_subset, on=['submission_id', 'subreddit_topic', 'search_query'], how='left')\n",
    "labeled_data = labeled_data[['submission_id', 'subreddit_topic', 'search_query', 'combine_text', 'url', 'label', 'reviewer']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop where it is in labeled but not in df \n",
    "labeled_data = labeled_data[~labeled_data['combine_text'].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conflicting labels:   1\n"
     ]
    }
   ],
   "source": [
    "# Make sure there are no duplicates in labeling \n",
    "combined_labeled_data_grouped = pd.DataFrame(labeled_data.groupby(['submission_id','subreddit_topic','search_query', 'combine_text', 'url']).agg({'label': ['count', 'min', 'max']})).reset_index()\n",
    "combined_labeled_data_grouped.columns = ['_'.join(col) for col in combined_labeled_data_grouped.columns]\n",
    "\n",
    "# Check if there are instances that the labels are not the same \n",
    "combined_labeled_data_grouped[combined_labeled_data_grouped['label_count'] > 1]\n",
    "combined_labeled_data_grouped['same_value'] = combined_labeled_data_grouped['label_min'] == combined_labeled_data_grouped['label_max']\n",
    "print(\"Number of conflicting labels:  \", combined_labeled_data_grouped[~combined_labeled_data_grouped['same_value']].shape[0])\n",
    "\n",
    "# Drop instances where the label was conflicting\n",
    "conflicting_submission_ids = list(combined_labeled_data_grouped[~combined_labeled_data_grouped['same_value']]['submission_id_'])\n",
    "labeled_data = labeled_data[~labeled_data['submission_id'].isin(conflicting_submission_ids)].reset_index(drop=True)\n",
    "\n",
    "# The ones that have more than 1 and are the same value , coalesce those \n",
    "labeled_data = labeled_data.drop_duplicates(\n",
    "    subset=['submission_id', 'subreddit_topic', 'search_query', 'combine_text', 'url'], \n",
    "    keep='first'\n",
    ").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conflicting labels:   1\n"
     ]
    }
   ],
   "source": [
    "combined_labeled_data_grouped['same_value'] = combined_labeled_data_grouped['label_min'] == combined_labeled_data_grouped['label_max']\n",
    "print(\"Number of conflicting labels:  \", combined_labeled_data_grouped[~combined_labeled_data_grouped['same_value']].shape[0])\n",
    "\n",
    "# Drop instances where the label was conflicting\n",
    "conflicting_submission_ids = list(combined_labeled_data_grouped[~combined_labeled_data_grouped['same_value']]['submission_id_'])\n",
    "labeled_data = labeled_data[~labeled_data['submission_id'].isin(conflicting_submission_ids)].reset_index(drop=True)\n",
    "\n",
    "# The ones that have more than 1 and are the same value , coalesce those \n",
    "labeled_data = labeled_data.drop_duplicates(\n",
    "    subset=['submission_id', 'subreddit_topic', 'search_query', 'combine_text', 'url'], \n",
    "    keep='first'\n",
    ").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral     78\n",
      "Negative    15\n",
      "Positive     2\n",
      "Name: label, dtype: int64\n",
      "\n",
      "\n",
      "Neutral     0.821053\n",
      "Negative    0.157895\n",
      "Positive    0.021053\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# See the distribution of the labels \n",
    "print(labeled_data['label'].value_counts(dropna=False) )\n",
    "print('\\n')\n",
    "print(labeled_data['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final file size:  95\n"
     ]
    }
   ],
   "source": [
    "print(\"Final file size: \",  labeled_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'combined_labeled_data.csv' uploaded successfully to folder 1Ktcv4eaR7kH0teyGuLph4LSYWxI1qkIS!\n"
     ]
    }
   ],
   "source": [
    "from access_data import  save_google_drive_data\n",
    "\n",
    "labeled_data_folder_location_file = \"credentials/google_drive_folder_id.json\"\n",
    "file_name_combined = \"combined_labeled_data.csv\"\n",
    "\n",
    "# Save the data in the Google Drive location\n",
    "save_google_drive_data(drive=drive, \n",
    "                       dataframe =labeled_data, \n",
    "                       filename=file_name_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
