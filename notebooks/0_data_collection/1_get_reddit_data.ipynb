{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Reddit Data\n",
    "\n",
    "This notebook will grab all the reddit data used. In order to run this notebook, the following need to be set up: \n",
    "1. **[PRAW API](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html)** created and saved within this directory in the file called \"credentials.json\". \n",
    "    - This will allow access to the Reddit data\n",
    "2. **[Google Drive API](https://developers.google.com/drive/api/quickstart/go)** created and saved within this directory in the file called \"client_secrets.json\"\n",
    "    - This will allow access to Google Drive to save the data in\n",
    "    - Also create the Google Drive Folder ID Credentials file (\"google_drive_credentials.json\") that will contain the folder id of the folder in google drive you'd like to save it to \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# set this on the path so that we can reference the commong data locations\n",
    "sys.path.append(\"../../scripts/\")\n",
    "from data_collection import load_credentials, combine_subreddits, posts_to_comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required packages\n",
    "import sys \n",
    "import json #needed to translate JSON data\n",
    "import requests #needed to perform HTTP GET and POST requests\n",
    "import pandas as pd\n",
    "import pprint # allows us to print more readable JSON data\n",
    "from datetime import datetime \n",
    "import time \n",
    "import io\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100) # Need this otherwise text columns will truncate!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 7.7.1 of praw is outdated. Version 7.8.1 was released Friday October 25, 2024.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged into Reddit successfully\n"
     ]
    }
   ],
   "source": [
    "# Load in the credentials\n",
    "reddit = load_credentials('credentials.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done pulling FirstTimeHomeBuyer subreddit for search term Rocket!\n",
      "Done pulling RealEstate subreddit for search term Rocket!\n",
      "Done pulling loanoriginators subreddit for search term Rocket!\n",
      "Done pulling homeowners subreddit for search term Rocket!\n",
      "Done pulling Mortgages subreddit for search term Rocket!\n",
      "Done pulling personalfinance subreddit for search term Rocket!\n",
      "Done pulling realtor subreddit for search term Rocket!\n",
      "Done pulling FirstTimeHomeBuyer subreddit for search term Fargo!\n",
      "Done pulling RealEstate subreddit for search term Fargo!\n",
      "Done pulling loanoriginators subreddit for search term Fargo!\n",
      "Done pulling homeowners subreddit for search term Fargo!\n",
      "Done pulling Mortgages subreddit for search term Fargo!\n",
      "Done pulling personalfinance subreddit for search term Fargo!\n",
      "Done pulling realtor subreddit for search term Fargo!\n",
      "====DONE!====\n",
      "(60, 9)\n",
      "--- Grabbed the data in: 0.07 minutes ---\n"
     ]
    }
   ],
   "source": [
    "n_posts = 5 # Start small!\n",
    "sub_reddits = ['FirstTimeHomeBuyer', 'RealEstate','loanoriginators', \n",
    "                'homeowners', 'Mortgages', 'personalfinance', 'realtor']\n",
    "search_terms = [\"Rocket\", \"Fargo\"]\n",
    "\n",
    "start_collect_time = time.time()\n",
    "\n",
    "# grab the posts\n",
    "reddit_data = combine_subreddits(reddit, n_posts, sub_reddits, search_terms)\n",
    "end_collect_time = time.time()\n",
    "time_elapsed = round((end_collect_time - start_collect_time)/60.0, 2)\n",
    "print(\"--- Grabbed the data in: %s minutes ---\" % (time_elapsed))\n",
    "\n",
    "# grab comments from posts\n",
    "# comments_combined_df = posts_to_comments(reddit_data)\n",
    "# time_elapsed = round(time.time() - end_collect_time, 3)\n",
    "# print(\"--- Grabbed comments from the posts in: %s seconds ---\" % (time_elapsed))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_collection import authenticate_google_drive, save_google_drive_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=209917166075-saupbq0ls0he9jdlpjrtscaio8kf1m7p.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n"
     ]
    }
   ],
   "source": [
    "# Grab the Google Drive object\n",
    "drive = authenticate_google_drive()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing file 'reddit_data.csv' deleted.\n",
      "File 'reddit_data.csv' uploaded successfully to folder 1kJ6TrI9MVT5mfnnYvS-OpRMJFVbIQ6Tl!\n"
     ]
    }
   ],
   "source": [
    "# Save the data in the Google Drive location\n",
    "save_google_drive_data(drive=drive, \n",
    "                       credential_file=\"google_drive_credentials.json\",  \n",
    "                       dataframe =reddit_data, \n",
    "                       filename=\"reddit_data.csv\")\n",
    "\n",
    "# save_google_drive_data(drive=drive, \n",
    "#                        credential_file=\"google_drive_credentials.json\",  \n",
    "#                        dataframe =comments_combined_df, \n",
    "#                        filename=\"reddit_comments_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can only save the data location locally temporarily and will need to delete \n",
    "# so that we can comply to Reddit policy \n",
    "# comments_combined_df.to_csv('../../data/comments.csv', index = False)\n",
    "# reddit_data.to_csv('../../data/posts.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test - Code to grab the data \n",
    "# from data_collection import grab_google_drive_folder_data\n",
    "\n",
    "# df = grab_google_drive_folder_data(filename=\"reddit_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
